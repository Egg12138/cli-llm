# cli-llm 1.0 for personal usage

- [x] custom model
- [x] more flexible prompt selector
- [ ] single file in Rust
- [x] local prompt manager
- [ ] fix error: after exiting, the LLM providers still keep generating, consuming huge amount of tokens
c. plugin support
6. single image input


# TODO


ussing LLM output formatter to specifiy the output format of LLM to get required context for furthor handle, for example display 
 
code blocks only


